<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[Unity] VR环境下的语音识别</title>
    <style type="text/css" media="all">
      body {
        margin: 0;
        font-family: "Helvetica Neue", Helvetica, Arial, "Hiragino Sans GB", sans-serif;
        font-size: 14px;
        line-height: 20px;
        color: #777;
        background-color: white;
      }
      .container {
        width: 700px;
        margin-right: auto;
        margin-left: auto;
      }

      .post {
        font-family: Georgia, "Times New Roman", Times, "SimSun", serif;
        position: relative;
        padding: 70px;
        bottom: 0;
        overflow-y: auto;
        font-size: 16px;
        font-weight: normal;
        line-height: 25px;
        color: #515151;
      }

      .post h1{
        font-size: 50px;
        font-weight: 500;
        line-height: 60px;
        margin-bottom: 40px;
        color: inherit;
      }

      .post p {
        margin: 0 0 35px 0;
      }

      .post img {
        border: 1px solid #D9D9D9;
      }

      .post a {
        color: #28A1C5;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="post">
        <h1 class="title">[Unity] VR环境下的语音识别</h1>
        <div class="show-content">
          <blockquote><p><b>语音识别对于VR领域格外重要，因为它不仅能模拟AI与用户对话，还为用户提供了与任意应用进行沟通的更多选择。</b>手动输入指令可能不太现实，并且应用如果拥有太多按钮或其它GUI元素，也会很快让用户手足无措。但只要能语音控制，那么在VR环境中就很容易开口去进行各种操作。</p></blockquote><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjE1MTkwMg==&amp;mid=2651038501&amp;idx=1&amp;sn=4cc05ecc25c196ecdfa95df66ad2b0a3&amp;chksm=bd1a94148a6d1d0266ceb762a2c5ff879260800acd8b23d99095d63841d947a3c137e939d8ce&amp;scene=21#wechat_redirect" target="_blank">Unity Labs</a>的虚拟现实（VR）授权平台Carte Blanche将发布一个名为U的个人助理系统，用户可以通过语音控制它，很便利地执行一些操作。<a href="http://mp.weixin.qq.com/s?__biz=MjM5NjE1MTkwMg==&amp;mid=2651038501&amp;idx=1&amp;sn=4cc05ecc25c196ecdfa95df66ad2b0a3&amp;chksm=bd1a94148a6d1d0266ceb762a2c5ff879260800acd8b23d99095d63841d947a3c137e939d8ce&amp;scene=21#wechat_redirect" target="_blank">Unity Labs研发团队</a>一直在研究可以实现这种声控命令的语音识别与分析工具。</p><p>观看下面的视频了解Carte Blanche中的个人助理系统U：</p><p>本文第一部分将介绍语音识别的概念和理论。它将简单介绍其相关概念和参考，以帮助读者了解更多关于语音识别方面的信息。第二部分将简单介绍在Unity Asset Store的安装包以及公开的代码库，我们封装了几个语音转文本的解决方案，还有一些用于对比各API的文本翻译的示例场景。</p><p><br></p><div class="image-package">
<img class="uploaded-img" src="http://upload-images.jianshu.io/upload_images/17266280-3173ef4da215a655.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="auto" height="auto"><br><div class="image-caption"></div>
</div><p>如果想详细了解语音识别的概念和理论以及更多相关的研究，请进入Unity官方中文社区。下面简单为大家介绍语音识别与语义分析的原理，以及<a href="http://mp.weixin.qq.com/s?__biz=MjM5NjE1MTkwMg==&amp;mid=2651038501&amp;idx=1&amp;sn=4cc05ecc25c196ecdfa95df66ad2b0a3&amp;chksm=bd1a94148a6d1d0266ceb762a2c5ff879260800acd8b23d99095d63841d947a3c137e939d8ce&amp;scene=21#wechat_redirect" target="_blank">Unity Labs</a>为大家提供的语音识别插件。</p><h1>语音识别与语义分析的原理</h1><p><b>语音识别，顾名思义就是通过程序将语音转换成文本</b>。而<b>语义分析是其下一步，即将转换出来的文本进一步分析</b>，并确定文本想要表达的意思。即使是目前最好的语音识别和语义分析程序也远称不上完美。虽然人们能直截了当并毫不费力地处理这样的任务，但是当我们试图让程序去执行这两个步骤时，困难程度真的是难以想象。</p><p>目前基于统计学的语音识别最重要的部分就是声学建模（Acoustic Modeling）。这个过程中用于识别声音开始时不同的波形，或者是语音结束时的一些音节。对于声学模型而言，通过查看声波输出，并尝试找出最可能输入的音节是什么， 从而分析出说话者究竟想表达什么。</p><p><br></p><div class="image-package">
<img class="uploaded-img" src="http://upload-images.jianshu.io/upload_images/17266280-6dbf93becd0581a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="auto" height="auto"><br><div class="image-caption"></div>
</div><p>如上图所示，这是声学模型中“x”的发音模型。椭圆表示我们正在尝试识别的音节。它们无法被直接观察到，但它们产生的概率波形（底部）是可以被完整观察到的。因此，波形自身是可以观察的，但必须及时从可观察的状态中分辨出音节。</p><p>假设语音已经被成功转换成了文本，现在程序需要分辨该文本究竟是什么“意思”，这时语义分析就可以登场了。人们日常生活中就无时不刻地在进行着语义分析。例如，在阅读这句话之前，你可能已经猜到接下来会是人们如何进行语义分析练习的例子。那是因为你能利用上一句（例如“人们日常生活中就无时不刻地在进行着语义分析”）作为上下文线索，从而很好地预测后续几句。因此，如果想要拥有非常逼真的VR体验，AI必须善于分析玩家的语句并给予正确的反馈。</p><h1>语音转文本的工具</h1><p>Labs最初研究的语音识别涉及了对现有语音转文本解决方案的评估。我们开发了整合部分解决方案的Unity C#脚本插件并分享在Unity Asset Store。里面包含了示例场景，可以依次对比每个API转换的文本内容，同时允许用户从给定的列表中选定短语，并查看说出该短语后程序判定的准确程度。该代码也可以从Unity代码库中获得。</p><p><br></p><div class="image-package">
<img class="uploaded-img" src="http://upload-images.jianshu.io/upload_images/17266280-949ee34bda7dbab8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="auto" height="auto"><br><div class="image-caption"></div>
</div><p>我们提供的插件是对比目前Unity中几大语音转文本解决方案的简便方法，也很容易将其整合至你的项目。如果想在Unity中尝试其他API，使用该插件也非常简单，只需新建类继承自Speech-To-Text的Service基类，然后即成到示例场景或小部件即可。除了单独的语音文本转换SDK，插件还包括多个辅助类与函数（记录管理器，音频文件的创建和转换等等），以便集成和比较更多的API。</p><p>各大语音文本都各有特色，如果有兴趣，可以查看关于<b>Windows dictation recognition, Google Cloud Speech, IBM Watson, 以及Wit.ai</b>四种语音识别解决方案的具体信息。</p><h1>总结与未来规划</h1><p>语音识别很难精准的原因在于有太多的变量需要考虑。对于每一种要识别的语言都需要储存大量的数据，包括所有现存的单词（包括俚语及简写形式），这些单词相互如何结合，语调和口音也可能影响发音，所有人类语言的冗余和矛盾等等更多因素。</p><p>发布至Asset Store的自Speech-To-Text插件目前仅集成了几个语音文本转换解决方案，但这些足以用来比较现有语音识别工具的优缺点了。对Unity开发者而言，该插件只是起点，还可以根据具体需求来加入更多功能。</p><p><i><br></i></p><div class="image-package">
<img class="uploaded-img" src="http://upload-images.jianshu.io/upload_images/17266280-fba39273d54d4f4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="auto" height="auto"><br><div class="image-caption"></div>
</div><p><i>SimSensei，一款由南加州（USC）学院创新研究部（ICT）开发出来的模拟治疗程序</i></p><p>这项研究源于Carte Blanche项目最初集成AI机器人U来响应声控命令的计划。这涉及到语音文本的转换以及关键字识别。另一个有趣却艰难的挑战是创造出能与用户“对话”的机器人。人们在日常对话中经常包含类似于“嗯”或者是“啊”之类的语气词来表达感受。如果VR应用中的AI机器人不仅能够理解关键字，还能理解人类回话的各个部分，那它将让VR环境的沉浸感进入全新的层次。</p>
        </div>
      </div>
    </div>
  </body>
</html>
